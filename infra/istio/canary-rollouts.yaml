# =============================================================================
# Argo Rollouts - Canary Deployment Strategy
# Progressive delivery with automated analysis
# =============================================================================

---
# API Canary Rollout
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: api-canary-rollout
  namespace: ml-scheduler
  labels:
    app: api
spec:
  replicas: 3
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
        - name: api
          image: ghcr.io/shri33/ml-task-scheduler/api:stable
          ports:
            - containerPort: 3000
              name: http
            - containerPort: 3001
              name: metrics
          envFrom:
            - secretRef:
                name: app-secrets
            - configMapRef:
                name: app-config
          resources:
            requests:
              cpu: 200m
              memory: 256Mi
            limits:
              cpu: 1
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health/ready
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
  strategy:
    canary:
      # Traffic routing steps
      steps:
        - setWeight: 5
        - pause: {duration: 2m}
        - analysis:
            templates:
              - templateName: success-rate-canary
        - setWeight: 10
        - pause: {duration: 5m}
        - analysis:
            templates:
              - templateName: success-rate-canary
              - templateName: latency-check
        - setWeight: 25
        - pause: {duration: 10m}
        - analysis:
            templates:
              - templateName: success-rate-canary
              - templateName: latency-check
        - setWeight: 50
        - pause: {duration: 10m}
        - analysis:
            templates:
              - templateName: success-rate-canary
              - templateName: latency-check
              - templateName: error-rate
        - setWeight: 75
        - pause: {duration: 5m}
        - setWeight: 100
      
      # Canary service
      canaryService: api-canary
      stableService: api-stable
      
      # Traffic routing via Istio
      trafficRouting:
        istio:
          virtualService:
            name: api-canary
            routes:
              - primary
          destinationRule:
            name: api-destination
            canarySubsetName: canary
            stableSubsetName: stable
      
      # Anti-affinity
      antiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution: {}
      
      # Max unavailable during rollout
      maxUnavailable: 1
      maxSurge: 2

---
# Analysis Template - Success Rate
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate-canary
  namespace: ml-scheduler
spec:
  metrics:
    - name: success-rate
      interval: 30s
      count: 5
      successCondition: result[0] >= 0.95
      failureLimit: 2
      provider:
        prometheus:
          address: http://prometheus.monitoring:9090
          query: |
            sum(rate(http_requests_total{
              app="api",
              version="canary",
              status=~"2.."
            }[5m])) 
            / 
            sum(rate(http_requests_total{
              app="api",
              version="canary"
            }[5m]))

---
# Analysis Template - Latency Check
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: latency-check
  namespace: ml-scheduler
spec:
  metrics:
    - name: p95-latency
      interval: 30s
      count: 5
      successCondition: result[0] < 0.5
      failureLimit: 2
      provider:
        prometheus:
          address: http://prometheus.monitoring:9090
          query: |
            histogram_quantile(0.95,
              sum(rate(http_request_duration_seconds_bucket{
                app="api",
                version="canary"
              }[5m])) by (le)
            )

---
# Analysis Template - Error Rate
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: error-rate
  namespace: ml-scheduler
spec:
  metrics:
    - name: error-rate
      interval: 30s
      count: 5
      successCondition: result[0] < 0.01
      failureLimit: 2
      provider:
        prometheus:
          address: http://prometheus.monitoring:9090
          query: |
            sum(rate(http_requests_total{
              app="api",
              version="canary",
              status=~"5.."
            }[5m])) 
            / 
            sum(rate(http_requests_total{
              app="api",
              version="canary"
            }[5m]))

---
# Canary Service
apiVersion: v1
kind: Service
metadata:
  name: api-canary
  namespace: ml-scheduler
spec:
  ports:
    - port: 80
      targetPort: 3000
      name: http
  selector:
    app: api

---
# Stable Service
apiVersion: v1
kind: Service
metadata:
  name: api-stable
  namespace: ml-scheduler
spec:
  ports:
    - port: 80
      targetPort: 3000
      name: http
  selector:
    app: api
